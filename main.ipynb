{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import h5py\n","import io\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras.utils import img_to_array, load_img\n","\n","test_images_path = 'test-image.hdf5'\n","\n","def get_images_dataframe(hdf5_file_path: str) -> pd.DataFrame:\n","\n","    image_arrays = []\n","\n","    with h5py.File(hdf5_file_path, 'r') as f:\n","\n","        for dataset_name in f.keys():\n","\n","            # Loading the image data from the current dataset\n","            # 'f[dataset_name][()]' retrieves the binary image data\n","            # 'io.BytesIO' converts the binary data into a format that can be read as an image\n","            image_grayscale = load_img(io.BytesIO(f[dataset_name][()]), color_mode='grayscale')\n","\n","            image_array = img_to_array(image_grayscale) / 255.0\n","\n","            flattened_image = tf.image.resize(image_array, (32, 32)).numpy().flatten()\n","\n","            # Adding a new column \"image_code\" to the table that stores the dataset name (unique identifier for each image)\n","            df_image_pixels = pd.DataFrame([flattened_image])\n","            df_image_pixels[\"image_code\"] = str(dataset_name)\n","            \n","            image_arrays.append(df_image_pixels)\n","\n","    return pd.concat(image_arrays, ignore_index=True)\n","\n","df_images = get_images_dataframe(test_images_path)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":9094797,"sourceId":63056,"sourceType":"competition"}],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":4}
