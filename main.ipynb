{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Load libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-08-10T15:07:55.024531Z","iopub.status.busy":"2024-08-10T15:07:55.024069Z","iopub.status.idle":"2024-08-10T15:08:12.698630Z","shell.execute_reply":"2024-08-10T15:08:12.697139Z","shell.execute_reply.started":"2024-08-10T15:07:55.024492Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-08-10 15:07:57.271323: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-08-10 15:07:57.271461: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-08-10 15:07:57.441892: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import os\n","import tensorflow.keras\n","import h5py\n","import io\n","\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import lightgbm as lgb\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n","from sklearn.metrics import precision_score, recall_score, classification_report, confusion_matrix, f1_score, roc_auc_score, confusion_matrix\n","from sklearn.preprocessing import StandardScaler, LabelEncoder, KBinsDiscretizer\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from imblearn.over_sampling import SMOTE\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense, Activation, LeakyReLU, ReLU, Flatten, BatchNormalization, Input, Reshape, Conv2D, MaxPooling2D\n","from tensorflow.keras.activations import relu,sigmoid,softmax"]},{"cell_type":"markdown","metadata":{},"source":["## Global variable initialization"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["TRAIN_IMAGES_PATH = '/kaggle/input/isic-2024-challenge/train-image.hdf5'\n","TEST_IMAGES_PATH = '/kaggle/input/isic-2024-challenge/test-image.hdf5'\n","\n","TRAIN_METADATA_PATH = '/kaggle/input/isic-2024-challenge/train-metadata.csv'\n","TEST_METADATA_PATH = '/kaggle/input/isic-2024-challenge/test-metadata.csv'"]},{"cell_type":"markdown","metadata":{},"source":["## Images processing function"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def process_image(hdf5_file_path: str) -> pd.DataFrame:\n","\n","    image_arrays = []\n","\n","    with h5py.File(hdf5_file_path, 'r') as f:\n","\n","        for dataset_name in f.keys():\n","\n","            # Loading the image data from the current dataset\n","            # 'f[dataset_name][()]' retrieves the binary image data\n","            # 'io.BytesIO' converts the binary data into a format that can be read as an image\n","            image_grayscale = load_img(io.BytesIO(f[dataset_name][()]), color_mode='grayscale')\n","\n","            image_array = img_to_array(image_grayscale) / 255.0\n","\n","            flattened_image = tf.image.resize(image_array, (32, 32)).numpy().flatten()\n","\n","            # Adding a new column \"image_code\" to the table that stores the dataset name (unique identifier for each image)\n","            df_image_pixels = pd.DataFrame([flattened_image])\n","            df_image_pixels[\"image_code\"] = str(dataset_name)\n","            \n","            image_arrays.append(df_image_pixels)\n","\n","    return pd.concat(image_arrays, ignore_index=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Metadata processing function"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def process_metadata(csv_file_path: str) -> pd.DataFrame:\n","    \n","    df_meta = pd.read_csv(\n","        csv_file_path,\n","        dtype = {\n","            'isic_id': 'string',\n","            'target': 'int64',\n","            'patient_id': 'string',\n","            'age_approx': 'float64',\n","            'sex': 'string',\n","            'anatom_site_general': 'string',\n","            'clin_size_long_diam_mm': 'float64',\n","            'image_type': 'string',\n","            'tbp_tile_type': 'string',\n","            'tbp_lv_A': 'float64',\n","            'tbp_lv_Aext': 'float64',\n","            'tbp_lv_B': 'float64',\n","            'tbp_lv_Bext': 'float64',\n","            'tbp_lv_C': 'float64',\n","            'tbp_lv_Cext': 'float64',\n","            'tbp_lv_H': 'float64',\n","            'tbp_lv_Hext': 'float64',\n","            'tbp_lv_L': 'float64',\n","            'tbp_lv_Lext': 'float64',\n","            'tbp_lv_areaMM2': 'float64',\n","            'tbp_lv_area_perim_ratio': 'float64',\n","            'tbp_lv_color_std_mean': 'float64',\n","            'tbp_lv_deltaA': 'float64',\n","            'tbp_lv_deltaB': 'float64',\n","            'tbp_lv_deltaL': 'float64',\n","            'tbp_lv_deltaLB': 'float64',\n","            'tbp_lv_deltaLBnorm': 'float64',\n","            'tbp_lv_eccentricity': 'float64',\n","            'tbp_lv_location': 'string',\n","            'tbp_lv_location_simple': 'string',\n","            'tbp_lv_minorAxisMM': 'float64',\n","            'tbp_lv_nevi_confidence': 'float64',\n","            'tbp_lv_norm_border': 'float64',\n","            'tbp_lv_norm_color': 'float64',\n","            'tbp_lv_perimeterMM': 'float64',\n","            'tbp_lv_radial_color_std_max': 'float64',\n","            'tbp_lv_stdL': 'float64',\n","            'tbp_lv_stdLExt': 'float64',\n","            'tbp_lv_symm_2axis': 'float64',\n","            'tbp_lv_symm_2axis_angle': 'int64',\n","            'tbp_lv_x': 'float64',\n","            'tbp_lv_y': 'float64',\n","            'tbp_lv_z': 'float64',\n","            'attribution': 'string',\n","            'copyright_license': 'string',\n","            'lesion_id': 'string',\n","            'iddx_full': 'string',\n","            'iddx_1': 'string',\n","            'iddx_2': 'string',\n","            'iddx_3': 'string',\n","            'iddx_4': 'string',\n","            'iddx_5': 'string',\n","            'mel_mitotic_index': 'string',\n","            'mel_thick_mm': 'float64',\n","            'tbp_lv_dnn_lesion_confidence': 'float64'\n","        }\n","    )\n","\n","    "]},{"cell_type":"markdown","metadata":{},"source":["# Load data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-06T09:00:31.406461Z","iopub.status.busy":"2024-08-06T09:00:31.405532Z","iopub.status.idle":"2024-08-06T09:00:37.495694Z","shell.execute_reply":"2024-08-06T09:00:37.494599Z","shell.execute_reply.started":"2024-08-06T09:00:31.406401Z"},"trusted":true},"outputs":[],"source":["df_train_images = process_image(TRAIN_IMAGES_PATH)\n","df_test_images = process_image(TEST_IMAGES_PATH)\n","\n","df_train_metadata = process_metadata(TRAIN_METADATA_PATH)\n","df_test_metadata = process_metadata(TEST_METADATA_PATH)"]},{"cell_type":"markdown","metadata":{},"source":["# Undersample the \"benign\"data for balancing purposes"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_meta.rename(columns={\"isic_id\": \"image_code\"}, inplace=True)\n","\n","merged_df = pd.merge(df, df_meta, on='image_code')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["benign_df = merged_df[merged_df['target'] == 0]\n","malign_df = merged_df[merged_df['target'] == 1]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["final_df = pd.concat([sampled_benign_df, malign_df])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image_columns = df.columns.tolist() \n","meta_columns = df_meta.columns.tolist()\n","\n","image_columns_with_target = image_columns + ['target']\n","\n","image_df = final_df[image_columns_with_target]\n","meta_df = final_df[meta_columns]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image_df[\"target\"].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["melanoma_counts = pd.Series({'benign': 3000, 'malign': 393})\n","\n","colors = ['lavender', 'pink']\n","bars = plt.bar(melanoma_counts.index, melanoma_counts, color=colors)\n","\n","for i, bar in enumerate(bars):\n","    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 1, \n","             str(melanoma_counts[i]), ha='center', va='bottom')\n","\n","plt.legend(bars, ['benign', 'malign'])\n","plt.title(\"Melanoma distribution after resampling\")\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Drop columns with a lot of nulls"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["meta_df.isnull().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["meta_df.drop(columns=[\"lesion_id\", \"iddx_2\", \"iddx_3\", \"iddx_4\", \"iddx_5\", \"mel_mitotic_index\", \"mel_thick_mm\"], inplace = True)"]},{"cell_type":"markdown","metadata":{},"source":["# Label encoding"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["enc = LabelEncoder()"]},{"cell_type":"markdown","metadata":{},"source":["#### Sex"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["meta_df['sex'].fillna('unkown',inplace = True)\n","df_meta['sex_enc'] = enc.fit_transform(df_meta.sex.astype('str'))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize = (5,3))\n","sns.countplot(x = 'sex', hue = 'target', data = meta_df, palette=\"pastel\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Anatom_site_general"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["meta_df.anatom_site_general = meta_df.anatom_site_general.fillna('unknown')\n","meta_df['anatom_enc']= enc.fit_transform(meta_df.anatom_site_general.astype('str'))"]},{"cell_type":"markdown","metadata":{},"source":["#### Age"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["meta_df['age_approx'] = meta_df['age_approx'].fillna(meta_df['age_approx'].mode().values[0])\n","meta_df['age_enc']= enc.fit_transform(meta_df['age_approx'].astype('str'))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize = (10,5))\n","sns.countplot(x = 'age_approx', hue = 'target', data = meta_df, palette=\"pastel\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Images per patient"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["meta_df['n_images'] = meta_df.patient_id.map(meta_df.groupby(['patient_id']).image_code.count())"]},{"cell_type":"markdown","metadata":{},"source":["#### Categorize number of images per patient"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["categorize = KBinsDiscretizer(n_bins = 10, encode = 'ordinal', strategy = 'uniform')\n","meta_df['n_images_enc'] = categorize.fit_transform(meta_df['n_images'].values.reshape(-1, 1)).astype(int).squeeze()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize = (6,3))\n","sns.countplot(x = 'n_images_enc', hue = 'target', data = meta_df, palette=\"pastel\")"]},{"cell_type":"markdown","metadata":{},"source":["#### tbp tile type"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["meta_df['tbp_tile_type_enc']= enc.fit_transform(meta_df.tbp_tile_type.astype('str'))"]},{"cell_type":"markdown","metadata":{},"source":["#### iddx_full"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["meta_df['iddx_full_enc']= enc.fit_transform(meta_df.iddx_full.astype('str'))"]},{"cell_type":"markdown","metadata":{},"source":["#### iddx-1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["meta_df['iddx_1_enc']= enc.fit_transform(meta_df.iddx_1.astype('str'))"]},{"cell_type":"markdown","metadata":{},"source":["#### tbp_lv_location"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["meta_df['tbp_lv_location_enc']= enc.fit_transform(meta_df.tbp_lv_location.astype('str'))"]},{"cell_type":"markdown","metadata":{},"source":["#### tbp_lv_location_simple"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["meta_df['tbp_lv_location_simple_enc']= enc.fit_transform(meta_df.tbp_lv_location_simple.astype('str'))"]},{"cell_type":"markdown","metadata":{},"source":["# metadata feature selection"]},{"cell_type":"markdown","metadata":{},"source":["#### drop columns not encoded"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["meta_df.drop(columns= [\n","   \"tbp_lv_location\", \"tbp_lv_location_simple\", \"patient_id\",\n","   \"age_approx\", \"sex\", \"anatom_site_general\", \"image_type\", \"tbp_tile_type\",\n","   \"tbp_lv_location\", \"tbp_lv_location_simple\", \"attribution\", \"copyright_license\",\n","   \"iddx_full\", \"iddx_1\"\n"," ], inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["#### make a copy for concat models later"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sprmdl_meta = meta_df.copy()\n","sprmdl_meta.head()"]},{"cell_type":"markdown","metadata":{},"source":["#### drop image code column"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["meta_df.drop(columns=[\"image_code\"], inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["#### correlation matrix"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["corr = meta_df.corr(method = 'pearson')\n","corr = corr.abs()\n","corr.style.background_gradient(cmap='inferno')"]},{"cell_type":"markdown","metadata":{},"source":["#### metadata features and target"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["meta_features = meta_df[\n","    [\n","        \"clin_size_long_diam_mm\", \"tbp_lv_A\",\n","        \"tbp_lv_Aext\", \"tbp_lv_B\", \"tbp_lv_Bext\", \"tbp_lv_C\", \"tbp_lv_Cext\",\n","        \"tbp_lv_H\", \"tbp_lv_Hext\", \"tbp_lv_L\", \"tbp_lv_Lext\", \"tbp_lv_areaMM2\",\n","        \"tbp_lv_color_std_mean\", \"tbp_lv_deltaA\", \"tbp_lv_deltaB\", \"tbp_lv_deltaL\",\n","        \"tbp_lv_deltaLB\", \"tbp_lv_deltaLBnorm\", \"tbp_lv_eccentricity\",\"iddx_full_enc\", \"iddx_1_enc\"\n","    ]\n","]\n","\n","\n","meta_target = meta_df[\"target\"]"]},{"cell_type":"markdown","metadata":{},"source":["# images features and target"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image_features = image_df.drop(columns=[\"image_code\", \"target\"])\n","\n","image_target = image_df[\"target\"]"]},{"cell_type":"markdown","metadata":{},"source":["# Train/test split"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["img_train, img_test, target_img_train, target_img_test = train_test_split(image_features, image_target, test_size = 0.20, random_state=0)\n","\n","meta_train, meta_test, target_meta_train, target_meta_test = train_test_split(meta_features, meta_target, test_size = 0.20, random_state=0)"]},{"cell_type":"markdown","metadata":{},"source":["# Normalize metadata"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["scaler = StandardScaler()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["scaler.fit(meta_train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["meta_train_norm = scaler.transform(meta_train)\n","\n","meta_test_norm = scaler.transform(meta_test)"]},{"cell_type":"markdown","metadata":{},"source":["# ML models building"]},{"cell_type":"markdown","metadata":{},"source":["## image model: CNN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["img_model = tf.keras.Sequential([\n","    tf.keras.layers.Reshape((32, 32, 1), input_shape=(1024,)), \n","    tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n","    tf.keras.layers.MaxPooling2D(),\n","    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n","    tf.keras.layers.MaxPooling2D(),\n","    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n","    tf.keras.layers.MaxPooling2D(),\n","    tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),\n","    tf.keras.layers.MaxPooling2D(),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(128, activation='relu'),  # Dense layer with 128 neurons\n","    tf.keras.layers.Dense(2)\n","    ])\n","\n","img_model.compile(optimizer='adam',\n","                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","                  metrics=['accuracy', 'mse'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["img_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["img_model.fit(img_train, target_img_train, epochs=10, validation_data=(img_test, target_img_test))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["img_predictions = img_model.predict(img_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\n","    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n","    .format(tumour[np.argmax(score)], 100 * np.max(score))\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## Metadata model: LightGBM"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["meta_d_train = lgb.Dataset(meta_train_norm, label=target_meta_train)\n","meta_d_test = lgb.Dataset(meta_test_norm, label=target_meta_test)\n","watchlist = [meta_d_train, meta_d_test]\n","\n","lgbm_params = {\n","    \"learning_rate\": 0.3,\n","    \"boosting_type\": \"dart\", #dart has been shown to prevent overfitting (see documentation)\n","    \"objective\": \"binary\",\n","    \"metric\": [\"auc\", \"binary_logloss\"],\n","    \"num_leaves\": 100,\n","    \"max_depth\": 10,\n","    'verbosity': -1\n","    }"]},{"cell_type":"markdown","metadata":{},"source":["### Stratified K-fold"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["N_FOLDS = 10\n","folds = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n","\n","oof = np.zeros(len(meta_train_norm))\n","sub = np.zeros(len(meta_test_norm))\n","\n","scores = [0 for _ in range(folds.n_splits)]\n","\n","# Cross-validation loop\n","for fold_, (train_idx, val_idx) in enumerate(folds.split(meta_train_norm, target_meta_train)):\n","    X_train, y_train = meta_train_norm[train_idx], target_meta_train.iloc[train_idx]\n","    X_val, y_val = meta_train_norm[val_idx], target_meta_train.iloc[val_idx]\n","    \n","    train_data = lgb.Dataset(X_train, label=y_train)\n","    val_data = lgb.Dataset(X_val, label=y_val)\n","    watchlist = [train_data, val_data]\n","    \n","    clf = lgb.train(lgbm_params, train_set=train_data, valid_sets=watchlist, num_boost_round=50)\n","    \n","    oof[val_idx] = clf.predict(X_val)\n","    sub += clf.predict(meta_test_norm) / folds.n_splits\n","    \n","    scores[fold_] = roc_auc_score(y_val, oof[val_idx])\n","    print(\"Fold {}: {}\".format(fold_ + 1, round(scores[fold_], 5)))\n","\n","\n","print(\"CV score (auc): {:<8.5f}, (std: {:<8.5f})\".format(roc_auc_score(target_meta_train, oof), np.std(scores)))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["meta_predictions = clf.predict(meta_test_norm)"]},{"cell_type":"markdown","metadata":{},"source":["#### Convert into binary values (0/1) for classification"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for i in range(meta_test_norm.shape[0]):\n","    if meta_predictions[i] >= 0.8:\n","        meta_predictions[i] = 1\n","    else:\n","        meta_predictions[i] = 0"]},{"cell_type":"markdown","metadata":{},"source":["#### Check model performance"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(f'Accuracy score: {metrics.accuracy_score(meta_predictions, target_meta_test)}')\n","print(f' ROC AUC score: {roc_auc_score(meta_predictions, target_meta_test)}')\n","print(classification_report(meta_predictions, target_meta_test))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cm_lgbm = confusion_matrix(target_meta_test, meta_predictions)\n","sns.heatmap(cm_lgbm, annot=True)"]},{"cell_type":"markdown","metadata":{},"source":["# Concat CNN and LGBM models"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sprmdl_meta_features = sprmdl_meta.drop(columns=[\"image_code\", \"target\"])\n","sprmdl_meta_target = sprmdl_meta[\"target\"]\n","sprmdl_meta_key = sprmdl_meta[\"image_code\"]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["scaler.fit(sprmdl_meta_features)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sprmdl_meta_features_norm = scaler.transform(sprmdl_meta_features)\n","\n","sprmdl_meta_features_norm = pd.DataFrame(sprmdl_meta_features_norm, columns = sprmdl_meta_features.columns)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sprmdl_meta_features_norm['image_code'] = sprmdl_meta_key\n","\n","sprmdl_meta_features_norm.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["supermodel_df = pd.merge(sprmdl_meta_features_norm, image_df, on='image_code')\n","supermodel_df.to_csv('supermodel_df.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image_columns = list(map(str, range(1024)))\n","metadata_columns = [col for col in supermodel_df.columns if col not in image_columns + ['image_code', 'target']]\n","\n","image_data = supermodel_df[image_columns].values\n","metadata_features = supermodel_df[metadata_columns].values\n","labels = supermodel_df['target'].values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define CNN model using API\n","inputs = Input(shape=(1024,))\n","x = Reshape((32, 32, 1))(inputs)\n","x = Conv2D(16, 3, padding='same', activation='relu')(x)\n","x = MaxPooling2D()(x)\n","x = Conv2D(32, 3, padding='same', activation='relu')(x)\n","x = MaxPooling2D()(x)\n","x = Conv2D(64, 3, padding='same', activation='relu')(x)\n","x = MaxPooling2D()(x)\n","x = Conv2D(128, 3, padding='same', activation='relu')(x)\n","x = MaxPooling2D()(x)\n","x = Flatten()(x)\n","x = Dense(128, activation='relu')(x)\n","outputs = Dense(2)(x)\n","\n","img_model = Model(inputs=inputs, outputs=outputs)\n","img_model.compile(optimizer='adam',\n","                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","                  metrics=['accuracy', 'mse'])\n","\n","\n","dummy_input = np.zeros((1, 1024)) # Call the model on some dummy data to ensure it is built\n","img_model.predict(dummy_input)\n","\n","feature_extractor = Model(inputs=img_model.input, outputs=img_model.layers[-2].output)\n","\n","supermodel_df = pd.read_csv('supermodel_df.csv')  #load the data\n","\n","image_columns = list(map(str, range(1024)))\n","metadata_columns = [col for col in supermodel_df.columns if col not in image_columns + ['image_code', 'target']]\n","\n","image_data = supermodel_df[image_columns].values\n","metadata_features = supermodel_df[metadata_columns].values\n","labels = supermodel_df['target'].values\n","\n","\n","cnn_features = feature_extractor.predict(image_data) #Extract features\n","\n","\n","combined_features = np.hstack((cnn_features, metadata_features)) # Combine CNN features with metadata\n","\n","\n","lgbm_params = {\n","    \"learning_rate\": 0.05,\n","    \"boosting_type\": \"dart\", #dart has been shown to prevent overfitting (see documentation)\n","    \"objective\": \"binary\",\n","    \"metric\": [\"auc\", \"binary_logloss\"],\n","    \"num_leaves\": 100,\n","    \"max_depth\": 10,\n","    'verbosity': -1\n","    }\n","\n","N_FOLDS = 10\n","folds = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n","\n","oof = np.zeros(len(combined_features))\n","sub = np.zeros(len(combined_features)) \n","\n","scores = [0 for _ in range(folds.n_splits)]\n","\n","for fold_, (train_idx, val_idx) in enumerate(folds.split(combined_features, labels)):\n","    X_train, y_train = combined_features[train_idx], labels[train_idx]\n","    X_val, y_val = combined_features[val_idx], labels[val_idx]\n","    \n","    train_data = lgb.Dataset(X_train, label=y_train)\n","    val_data = lgb.Dataset(X_val, label=y_val)\n","    watchlist = [train_data, val_data]\n","    \n","    clf = lgb.train(lgbm_params, train_set=train_data, valid_sets=watchlist, num_boost_round=50)\n","    \n","    oof[val_idx] = clf.predict(X_val)\n","    sub += clf.predict(combined_features) / folds.n_splits\n","    \n","    scores[fold_] = roc_auc_score(y_val, oof[val_idx])\n","    print(\"Fold {}: {}\".format(fold_ + 1, round(scores[fold_], 5)))\n","\n","print(\"CV AUC: {:.5f}\".format(roc_auc_score(labels, oof)))\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":9094797,"sourceId":63056,"sourceType":"competition"}],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":4}
